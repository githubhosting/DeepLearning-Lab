{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Program 11:\n\n#### Objective: \nImplement the Self-Attention mechanism using the PyTorch framework.\n\nTasks:\n- Define the Self-Attention mechanism.\n- Show the forward pass.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T19:17:28.857646Z","iopub.execute_input":"2024-07-10T19:17:28.858098Z","iopub.status.idle":"2024-07-10T19:17:28.863867Z","shell.execute_reply.started":"2024-07-10T19:17:28.858063Z","shell.execute_reply":"2024-07-10T19:17:28.862635Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super(SelfAttention, self).__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.query = nn.Linear(embed_dim, embed_dim)\n        self.key = nn.Linear(embed_dim, embed_dim)\n        self.value = nn.Linear(embed_dim, embed_dim)\n        self.out = nn.Linear(embed_dim, embed_dim)\n    \n    def forward(self, x):\n        batch_size, seq_len, embed_dim = x.size()\n        \n        # Compute Q, K, V matrices\n        Q = self.query(x)  # (batch_size, seq_len, embed_dim)\n        K = self.key(x)    # (batch_size, seq_len, embed_dim)\n        V = self.value(x)  # (batch_size, seq_len, embed_dim)\n        \n        # Split the embedding into multiple heads\n        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        \n        # Compute attention scores\n        attn_scores = torch.matmul(Q, K.transpose(-2,-1)) * self.scale\n        attn_weights = F.softmax(attn_scores, dim=-1)\n        \n        # Compute the weighted sum of the values\n        attn_output = torch.matmul(attn_weights, V)\n        \n        # Concatenate the multiple heads\n        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n        \n        # Apply the final linear layer\n        output = self.out(attn_output)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:17:29.687218Z","iopub.execute_input":"2024-07-10T19:17:29.687612Z","iopub.status.idle":"2024-07-10T19:17:29.701634Z","shell.execute_reply.started":"2024-07-10T19:17:29.687582Z","shell.execute_reply":"2024-07-10T19:17:29.700225Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Example usage\nembed_dim = 128\nnum_heads = 8\nseq_len = 10\nbatch_size = 32\n\nx = torch.randn(batch_size, seq_len, embed_dim)\nself_attention = SelfAttention(embed_dim, num_heads)\noutput = self_attention(x)\nprint(output.shape)  # Output shape will be (batch_size, seq_len, embed_dim)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T19:17:30.290321Z","iopub.execute_input":"2024-07-10T19:17:30.290816Z","iopub.status.idle":"2024-07-10T19:17:30.310840Z","shell.execute_reply.started":"2024-07-10T19:17:30.290778Z","shell.execute_reply":"2024-07-10T19:17:30.309507Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"torch.Size([32, 10, 128])\n","output_type":"stream"}]}]}