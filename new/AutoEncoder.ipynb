{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Program 9:\n\n#### Objective: \nImplement an AutoEncoder using the PyTorch framework.\n\nTasks:\n- Implement an AutoEncoder architecture.\n- Preprocess the dataset.\n- Define model training function.\n- Train model using suitable criterion and optimizer.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T15:42:44.950688Z","iopub.execute_input":"2024-07-10T15:42:44.951104Z","iopub.status.idle":"2024-07-10T15:42:45.422012Z","shell.execute_reply.started":"2024-07-10T15:42:44.951075Z","shell.execute_reply":"2024-07-10T15:42:45.420195Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Preprocess the dataset\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:42:53.445958Z","iopub.execute_input":"2024-07-10T15:42:53.446449Z","iopub.status.idle":"2024-07-10T15:42:53.452983Z","shell.execute_reply.started":"2024-07-10T15:42:53.446413Z","shell.execute_reply":"2024-07-10T15:42:53.451709Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n\ntrain_subset = Subset(train_dataset, range(200))\ntest_subset = Subset(test_dataset, range(50))\n\ntrain_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\ntest_loader = DataLoader(test_subset, batch_size=10, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Implement an AutoEncoder architecture\nclass AutoEncoder(nn.Module):\n    def __init__(self):\n        super(AutoEncoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(28*28, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, 64)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(64, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, 28*28),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:19.373724Z","iopub.execute_input":"2024-07-10T15:43:19.375267Z","iopub.status.idle":"2024-07-10T15:43:19.385058Z","shell.execute_reply.started":"2024-07-10T15:43:19.375216Z","shell.execute_reply":"2024-07-10T15:43:19.383181Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = AutoEncoder()\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.MSELoss()\n\n# Define model training function\ndef train_model(num_epochs):\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        for data in train_loader:\n            img, _ = data\n            img = img.view(img.size(0), -1)\n            output = model(img)\n            loss = criterion(output, img)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        avg_train_loss = train_loss / len(train_loader)\n\n        model.eval()\n        test_loss = 0.0\n        with torch.no_grad():\n            for data in test_loader:\n                img, _ = data\n                img = img.view(img.size(0), -1)\n                output = model(img)\n                loss = criterion(output, img)\n                test_loss += loss.item()\n        avg_test_loss = test_loss / len(test_loader)\n        \n        print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:48.088970Z","iopub.execute_input":"2024-07-10T15:43:48.089467Z","iopub.status.idle":"2024-07-10T15:43:48.107935Z","shell.execute_reply.started":"2024-07-10T15:43:48.089431Z","shell.execute_reply":"2024-07-10T15:43:48.106355Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Train model using suitable criterion and optimizer\ntrain_model(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:56.469370Z","iopub.execute_input":"2024-07-10T15:43:56.469895Z","iopub.status.idle":"2024-07-10T15:43:57.726406Z","shell.execute_reply.started":"2024-07-10T15:43:56.469857Z","shell.execute_reply":"2024-07-10T15:43:57.725295Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1, Train Loss: 0.1341, Test Loss: 0.0754\nEpoch 2, Train Loss: 0.0730, Test Loss: 0.0708\nEpoch 3, Train Loss: 0.0691, Test Loss: 0.0671\nEpoch 4, Train Loss: 0.0635, Test Loss: 0.0637\nEpoch 5, Train Loss: 0.0577, Test Loss: 0.0583\nEpoch 6, Train Loss: 0.0518, Test Loss: 0.0521\nEpoch 7, Train Loss: 0.0450, Test Loss: 0.0485\nEpoch 8, Train Loss: 0.0397, Test Loss: 0.0445\nEpoch 9, Train Loss: 0.0358, Test Loss: 0.0429\nEpoch 10, Train Loss: 0.0330, Test Loss: 0.0408\n","output_type":"stream"}]}]}