{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Program 9:\n","\n","#### Objective: \n","Implement an AutoEncoder using the PyTorch framework.\n","\n","Tasks:\n","- Implement an AutoEncoder architecture.\n","- Preprocess the dataset.\n","- Define model training function.\n","- Train model using suitable criterion and optimizer."]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-10T15:42:44.951104Z","iopub.status.busy":"2024-07-10T15:42:44.950688Z","iopub.status.idle":"2024-07-10T15:42:45.422012Z","shell.execute_reply":"2024-07-10T15:42:45.420195Z","shell.execute_reply.started":"2024-07-10T15:42:44.951075Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([transforms.ToTensor()])\n","\n","train_dataset = datasets.MNIST(root=\"./data\", train=True, download=False, transform=transform)\n","test_dataset = datasets.MNIST(root=\"./data\", train=False, download=False, transform=transform)\n","\n","train_subset = Subset(train_dataset, range(200))\n","test_subset = Subset(test_dataset, range(50))\n","\n","train_loader = DataLoader(train_subset, batch_size=10, shuffle=True)\n","test_loader = DataLoader(test_subset, batch_size=10, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T15:43:19.375267Z","iopub.status.busy":"2024-07-10T15:43:19.373724Z","iopub.status.idle":"2024-07-10T15:43:19.385058Z","shell.execute_reply":"2024-07-10T15:43:19.383181Z","shell.execute_reply.started":"2024-07-10T15:43:19.375216Z"},"trusted":true},"outputs":[],"source":["class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(28 * 28, 256), nn.ReLU(inplace=True), nn.Linear(256, 64)\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(64, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(256, 28 * 28),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T15:43:48.089467Z","iopub.status.busy":"2024-07-10T15:43:48.088970Z","iopub.status.idle":"2024-07-10T15:43:48.107935Z","shell.execute_reply":"2024-07-10T15:43:48.106355Z","shell.execute_reply.started":"2024-07-10T15:43:48.089431Z"},"trusted":true},"outputs":[],"source":["model = AutoEncoder()\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.MSELoss()\n","\n","\n","def train_model(num_epochs):\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        for data in train_loader:\n","            img, _ = data\n","            img = img.view(img.size(0), -1)\n","            output = model(img)\n","            loss = criterion(output, img)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","        avg_train_loss = train_loss / len(train_loader)\n","\n","        model.eval()\n","        test_loss = 0.0\n","        with torch.no_grad():\n","            for data in test_loader:\n","                img, _ = data\n","                img = img.view(img.size(0), -1)\n","                output = model(img)\n","                loss = criterion(output, img)\n","                test_loss += loss.item()\n","        avg_test_loss = test_loss / len(test_loader)\n","\n","        print(\n","            f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\"\n","        )"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T15:43:56.469895Z","iopub.status.busy":"2024-07-10T15:43:56.469370Z","iopub.status.idle":"2024-07-10T15:43:57.726406Z","shell.execute_reply":"2024-07-10T15:43:57.725295Z","shell.execute_reply.started":"2024-07-10T15:43:56.469857Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Train Loss: 0.1341, Test Loss: 0.0754\n","Epoch 2, Train Loss: 0.0730, Test Loss: 0.0708\n","Epoch 3, Train Loss: 0.0691, Test Loss: 0.0671\n","Epoch 4, Train Loss: 0.0635, Test Loss: 0.0637\n","Epoch 5, Train Loss: 0.0577, Test Loss: 0.0583\n","Epoch 6, Train Loss: 0.0518, Test Loss: 0.0521\n","Epoch 7, Train Loss: 0.0450, Test Loss: 0.0485\n","Epoch 8, Train Loss: 0.0397, Test Loss: 0.0445\n","Epoch 9, Train Loss: 0.0358, Test Loss: 0.0429\n","Epoch 10, Train Loss: 0.0330, Test Loss: 0.0408\n"]}],"source":["# Train model using suitable criterion and optimizer\n","train_model(10)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
