{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Program 10:\n\n#### Objective: \nImplement a Generative Adversarial Network (GAN) on the MNIST dataset using the PyTorch framework.\n\nTasks:\n- Define a GAN architecture.\n- Preprocess the MNIST dataset.\n- Define model training function.\n- Train model using suitable criterion and optimizer.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T18:41:31.396822Z","iopub.execute_input":"2024-07-10T18:41:31.397242Z","iopub.status.idle":"2024-07-10T18:41:37.227568Z","shell.execute_reply.started":"2024-07-10T18:41:31.397207Z","shell.execute_reply":"2024-07-10T18:41:37.226231Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Preprocess the dataset\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:41:37.230063Z","iopub.execute_input":"2024-07-10T18:41:37.230969Z","iopub.status.idle":"2024-07-10T18:41:37.237005Z","shell.execute_reply.started":"2024-07-10T18:41:37.230921Z","shell.execute_reply":"2024-07-10T18:41:37.235570Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\nsubset = Subset(dataset, range(1000))\ndataloader = DataLoader(subset, batch_size=10, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define Generator and Discriminator architectures\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            nn.Linear(100, 256),\n            nn.ReLU(),\n            nn.Linear(256, 28*28),\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        return self.gen(x)\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            nn.Linear(28*28, 256),\n            nn.ReLU(),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:41:45.138293Z","iopub.execute_input":"2024-07-10T18:41:45.138720Z","iopub.status.idle":"2024-07-10T18:41:45.149649Z","shell.execute_reply.started":"2024-07-10T18:41:45.138686Z","shell.execute_reply":"2024-07-10T18:41:45.147906Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize models, criterion, and optimizers\ngenerator = Generator()\ndiscriminator = Discriminator()\ncriterion = nn.BCELoss()\noptim_gen = optim.Adam(generator.parameters(), lr=2e-4)\noptim_disc = optim.Adam(discriminator.parameters(), lr=2e-4)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:42:01.084772Z","iopub.execute_input":"2024-07-10T18:42:01.085217Z","iopub.status.idle":"2024-07-10T18:42:01.115417Z","shell.execute_reply.started":"2024-07-10T18:42:01.085182Z","shell.execute_reply":"2024-07-10T18:42:01.114098Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define model training function\ndef train(num_epochs):\n    for epoch in range(num_epochs):\n        generator.train()\n        discriminator.train()\n        for real, _ in dataloader:\n            real = real.view(-1, 28*28)\n            batch_size = real.size(0)\n            \n            # Train Discriminator\n            noise = torch.randn(batch_size, 100)\n            fake = generator(noise)\n            disc_real = discriminator(real)\n            loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n            disc_fake = discriminator(fake)\n            loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n            loss_disc = (loss_disc_real + loss_disc_fake) / 2\n            \n            # Backpropagation\n            optim_disc.zero_grad()\n            loss_disc.backward()\n            optim_disc.step()\n            \n            # Train Generator\n            noise = torch.randn(batch_size, 100)\n            fake = generator(noise)\n            disc_fake = discriminator(fake)\n            loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n            \n            # Backpropagation\n            optim_gen.zero_grad()\n            loss_gen.backward()\n            optim_gen.step()\n        \n        print(f'Epoch {epoch+1}, Loss D: {loss_disc.item():.4f}, Loss G: {loss_gen.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:42:15.497839Z","iopub.execute_input":"2024-07-10T18:42:15.498306Z","iopub.status.idle":"2024-07-10T18:42:15.511580Z","shell.execute_reply.started":"2024-07-10T18:42:15.498266Z","shell.execute_reply":"2024-07-10T18:42:15.509725Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Train model\ntrain(10)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T18:42:40.166282Z","iopub.execute_input":"2024-07-10T18:42:40.166722Z","iopub.status.idle":"2024-07-10T18:42:48.925234Z","shell.execute_reply.started":"2024-07-10T18:42:40.166686Z","shell.execute_reply":"2024-07-10T18:42:48.923954Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1, Loss D: 0.4740, Loss G: 1.0638\nEpoch 2, Loss D: 0.2743, Loss G: 2.1483\nEpoch 3, Loss D: 0.5469, Loss G: 1.3955\nEpoch 4, Loss D: 0.6319, Loss G: 1.3669\nEpoch 5, Loss D: 0.3785, Loss G: 1.5520\nEpoch 6, Loss D: 0.4248, Loss G: 1.5853\nEpoch 7, Loss D: 0.4559, Loss G: 1.4561\nEpoch 8, Loss D: 0.3577, Loss G: 1.5788\nEpoch 9, Loss D: 0.3876, Loss G: 1.4889\nEpoch 10, Loss D: 0.2887, Loss G: 1.3170\n","output_type":"stream"}]}]}